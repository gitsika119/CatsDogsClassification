{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXT9WL8aUo76KfvB8F+sbq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gitsika119/CatsDogsClassification/blob/main/catdogclass.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "KAgd4YSfGvCE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbd55376-f577-4ed6-f8e6-dcbc16a7d7fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-10-27 07:46:21--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.101.207, 142.251.2.207, 142.250.141.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.101.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "/tmp/cats_and_dogs_ 100%[===================>]  65.43M  83.2MB/s    in 0.8s    \n",
            "\n",
            "2024-10-27 07:46:22 (83.2 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n",
            "Epoch 1/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 38s/step - accuracy: 0.8000 - loss: 0.3688\n",
            "Epoch 2/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step - accuracy: 1.0000 - loss: 0.0270\n",
            "Epoch 3/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step - accuracy: 1.0000 - loss: 0.0014\n",
            "Epoch 4/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 2.3051e-04\n",
            "Epoch 5/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 8.4699e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a0fc444a7d0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "!wget --no-check-certificate \\https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "-O /tmp/cats_and_dogs_filtered.zip\n",
        "import os\n",
        "import zipfile\n",
        "local_zip='/tmp/cats_and_dogs_filtered.zip'\n",
        "zip_ref=zipfile.ZipFile(local_zip,'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "base_dir='/tmp/cats_and_dogs_filtered'\n",
        "train_dir=os.path.join(base_dir,'train')\n",
        "validation_dir=os.path.join(base_dir,'validation')\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "NUMBER_OF_EXAMPLES=10\n",
        "x_train=[]\n",
        "y_train=[]\n",
        "cats_dir=os.path.join(train_dir,'cats')\n",
        "dogs_dir=os.path.join(train_dir,'dogs')\n",
        "i=0\n",
        "while i<NUMBER_OF_EXAMPLES:\n",
        "  if (i%2==0):\n",
        "    im=Image.open(os.path.join(cats_dir,os.listdir(cats_dir)[i])).convert(\"RGB\")\n",
        "    im_resized=im.resize((150,150))\n",
        "    x_train.append(np.array(im_resized))\n",
        "    y_train.append(1)\n",
        "  else:\n",
        "    im=Image.open(os.path.join(dogs_dir,os.listdir(dogs_dir)[i])).convert(\"RGB\")\n",
        "    im_resized=im.resize((150,150))\n",
        "    x_train.append(np.array(im_resized))\n",
        "    y_train.append(1)\n",
        "  i+=1\n",
        "import tensorflow as tf\n",
        "model=tf.keras.models.Sequential()\n",
        "pretrained_model=tf.keras.applications.ResNet50V2(include_top=False,weights='imagenet',input_shape=(150,150,3),pooling='avg',classes=2)\n",
        "model.add(pretrained_model)\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(64,activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(2,activation='softmax'))\n",
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "x_train=np.array(x_train)\n",
        "y_train=np.array(y_train)\n",
        "model.fit(x_train,y_train,epochs=5)\n"
      ]
    }
  ]
}